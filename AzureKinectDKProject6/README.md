# Project 6

This file contains my own scripts made using the pykinect-azure wrapper.

### BodyTracking3dModel.py
Extracts joint data from body tracking SDK and visualises it in realtime in 3D using model3dEngine
Eventually stopped using it because the body tracking ai and the ursina engine together caused too much lag.
Note: there may be lots of delay and lag, not reccommended on CPU (what I used).

### BodyTracking3dModelPlayback.py
Extracts pre-recorded joint data and visualises it in 3D using model3dEngine.
This is what I'm using as of October 2023.
Uses the nodeCoordinateRecorder module to recover previously recorded joint data.
Note: currently only works for pickle format.
Note: you need to change the file location of the data manually in the code.
Use this to visualise joint data!

### ExtractJointData_ShellOnly.py
Oldest script here, simply records and prints the joint data to the terminal.

### model3dEngine
Module used to visualise the point clouds generated by the Body Tracking SDK in 3D.
Builds on the Ursina engine.

### nodeCoordinateRecorder.py
Module used to both record joint data point clouds and restore said data to original format.
Currently only stores joint data in pickle format.

### OutputPickleContentsTool.py
Script to quickly output the joint data point clouds recorded in a file using nodeCoordinateRecorder.
Used for quick debugging.
Note: you need to change the file location of the data manually in the code.

### RecordingFromIDLE.txt
This is a copy of the joint coordinates obtained during a body tracking recording.
Mainly used to visualise what the data looks like.

### RecordJointData_jsonFormat.py
Extracts joint data and stores in json format.
DOESN'T WORK! DO NOT USE!

### RecordJointData_pickleFormat.py
Extracts joint data from body tracking SDK and stores it in pickle format using nodeCoordinateRecorder.
Run this to record joint data!

### requirements.txt
Holds the modules needed to run the code in this file, as well as the versions I was using in my environment.